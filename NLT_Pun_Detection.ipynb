{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RwEwboy6QAv",
        "outputId": "7a70dfa0-c87a-435c-ad8b-fc5c3bc97c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pronouncing in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cmudict>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pronouncing) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.12/dist-packages (from cmudict>=0.4.0->pronouncing) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.12/dist-packages (from cmudict>=0.4.0->pronouncing) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing) (3.23.0)\n",
            "Requirement already satisfied: phonetics in /usr/local/lib/python3.12/dist-packages (1.0.5)\n"
          ]
        }
      ],
      "source": [
        "#!pip install pronouncing\n",
        "#!pip install phonetics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qza5GhNtz02"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDIYtI90iXsQDsIOytwdrFBeaIeVEwjnTs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlKdLZb9OwvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d91767-182a-4481-ff47-ef2593abc580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ AoA entries loaded: 31,104\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_aoa(path=\"/content/drive/MyDrive/Colab Notebooks/AoA_ratings_Kuperman_et_al_BRM_with_PoS.xlsx\"):\n",
        "    try:\n",
        "        df = pd.read_excel(path)\n",
        "        w = next((c for c in df.columns if \"word\" in c.lower()), \"Word\")\n",
        "        r = next((c for c in df.columns if any(k in c.lower() for k in [\"aoa\",\"mean\",\"rating\"])), \"Rating.Mean\")\n",
        "        df = df[[w,r]].dropna()\n",
        "        df[w] = df[w].astype(str).str.lower()\n",
        "        print(f\"✅ AoA entries loaded: {len(df):,}\")\n",
        "        return dict(zip(df[w], df[r]))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ AoA file not found or error loading: {e} — using fallback.\")\n",
        "        return {} # Return an empty dictionary or None as a fallback\n",
        "\n",
        "AOA = load_aoa()\n",
        "\n",
        "\n",
        "def aoa_penalty(word, age):\n",
        "    val = AOA.get(word.lower())\n",
        "    if val is None:\n",
        "        print(f\"Word '{word}' has not been found in AoA Dict.\")\n",
        "        return None # Or return a default penalty or value\n",
        "    try:\n",
        "        age = float(age)\n",
        "        return print(f'{age > val} : The word is suitable for age greater than:{val:.2f}')\n",
        "    except ValueError:\n",
        "        print(f\"Invalid age provided: {age}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaBy6xH3PGZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7196c60e-26ee-41fa-efd3-37695e90de3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLSA_rKWwVnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456c58fa-b5a2-462b-e4bc-881a93b28548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversational Agent (memory on) — type 'quit' to exit.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import json, re, time\n",
        "from typing import Dict, Any, Optional, Tuple\n",
        "\n",
        "# ---------- Word-wrap helper (≤10 words per line) ----------\n",
        "def _wrap_by_words(text: str, max_words: int = 10) -> str:\n",
        "    words = text.split()\n",
        "    if not words:\n",
        "        return \"\"\n",
        "    lines, cur = [], []\n",
        "    for w in words:\n",
        "        cur.append(w)\n",
        "        if len(cur) >= max_words:\n",
        "            lines.append(\" \".join(cur))\n",
        "            cur = []\n",
        "    if cur:\n",
        "        lines.append(\" \".join(cur))\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# --- small utility (define if not in scope) ---\n",
        "def _safe_take_text(gen_response):\n",
        "    if hasattr(gen_response, \"text\") and gen_response.text:\n",
        "        return gen_response.text\n",
        "    try:\n",
        "        cands = getattr(gen_response, \"candidates\", [])\n",
        "        for c in cands:\n",
        "            content = getattr(c, \"content\", None)\n",
        "            parts = content.get(\"parts\", []) if isinstance(content, dict) else getattr(content, \"parts\", [])\n",
        "            for p in parts or []:\n",
        "                t = getattr(p, \"text\", None)\n",
        "                if t: return t\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"\"\n",
        "\n",
        "def _parse_pair_label(lbl: str) -> Tuple[Optional[str], Optional[str], bool, Optional[float]]:\n",
        "    if not lbl or lbl.strip().lower() == \"none\":\n",
        "        return None, None, False, None\n",
        "    implicit = \"[implicit]\" in lbl\n",
        "    m = re.search(r\"\\(([^,]+),\\s*([^)]+)\\)\", lbl)\n",
        "    w1, w2 = (m.group(1).strip(), m.group(2).strip()) if m else (None, None)\n",
        "    ms = re.search(r\"similarity:\\s*([0-9.]+)\", lbl)\n",
        "    score = float(ms.group(1)) if ms else None\n",
        "    return w1, w2, implicit, score\n",
        "\n",
        "# ── LLM prompt for choosing the pair (ignore upstream pairs; pick your own) ───\n",
        "_CHOOSE_PAIR_INSTRUCTIONS = \"\"\"\n",
        "You are assisting a pun/wordplay detector. You will receive:\n",
        "- The input sentence (text) and age\n",
        "- The detector's coarse verdict about pun type: one of {\"phonetic\",\"semantic\",\"non-joke\"}.\n",
        "\n",
        "Your task:\n",
        "1) Choose EXACTLY ONE candidate pair using your reasoning (do not rely on earlier candidate strings).\n",
        "   They must be two different words.\n",
        "   • If pun_type == \"phonetic\": you may pick an implicit phonetic partner; it need not both appear in text.\n",
        "   • If pun_type == \"semantic\": pick two different words that appear in the given text and are meaning-related for the joke.\n",
        "2) If pun_type == \"non-joke\", set chosen_type=\"none\" and return empty pair.\n",
        "3) Return STRICT JSON (no markdown, no extra text):\n",
        "{\n",
        "  \"chosen_type\": \"phonetic\" | \"semantic\" | \"none\",\n",
        "  \"w1\": \"<first word or empty>\",\n",
        "  \"w2\": \"<second word or empty>\",\n",
        "  \"why\": \"one short sentence\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def llm_choose_pair(text: str, age: float, pun_type_hint: str, retries: int = 1) -> Dict[str, Any]:\n",
        "    payload = {\"text\": text, \"age\": age, \"pun_type_hint\": pun_type_hint}\n",
        "    prompt = (\n",
        "        _CHOOSE_PAIR_INSTRUCTIONS\n",
        "        + \"\\n\\nINPUT:\\n\"\n",
        "        + json.dumps(payload, ensure_ascii=False, indent=2)\n",
        "        + \"\\n\\nOUTPUT JSON ONLY:\"\n",
        "    )\n",
        "    last_err = None\n",
        "    for i in range(retries + 1):\n",
        "        try:\n",
        "            r = model_llm.generate_content(prompt)\n",
        "            ans = _safe_take_text(r).strip()\n",
        "            ans = re.sub(r'^\\s*```(?:json)?\\s*', '', ans)\n",
        "            ans = re.sub(r'\\s*```\\s*$', '', ans).strip()\n",
        "            m = re.search(r'\\{.*\\}', ans, re.DOTALL)\n",
        "            if m: ans = m.group(0)\n",
        "            data = json.loads(ans)\n",
        "            ctype = str(data.get(\"chosen_type\", \"none\")).lower()\n",
        "            if ctype not in {\"phonetic\", \"semantic\", \"none\"}:\n",
        "                ctype = \"none\"\n",
        "            w1 = (data.get(\"w1\") or \"\").strip()\n",
        "            w2 = (data.get(\"w2\") or \"\").strip()\n",
        "            why = (data.get(\"why\") or \"\").strip()\n",
        "            if w1 and w2 and w1.lower() == w2.lower():\n",
        "                ctype, w1, w2 = \"none\", \"\", \"\"\n",
        "            return {\"chosen_type\": ctype, \"w1\": w1, \"w2\": w2, \"why\": why}\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if i < retries and any(x in str(e) for x in (\"429\", \"503\")):\n",
        "                time.sleep(1.5 * (i + 1)); continue\n",
        "            break\n",
        "    return {\"chosen_type\": \"none\", \"w1\": \"\", \"w2\": \"\", \"why\": f\"[LLM choose error] {str(last_err)[:160]}\"}\n",
        "\n",
        "# ── LLM QA constrained to SELECTED pair (for follow-ups & uncommon Qs) ───────\n",
        "_QA_SELECTED_PAIR_INSTRUCTIONS = \"\"\"\n",
        "You answer questions about the detected wordplay using ONLY the SELECTED pair and its channel.\n",
        "Do not invent new pairs. Be concise and plain text.\n",
        "If asked “what kind of wordplay,” answer with {phonetic|semantic|none} and one short reason.\n",
        "Do not report any similarity score unless the user explicitly asks for it.\n",
        "\"\"\"\n",
        "\n",
        "def qa_on_selected(question: str, state, retries: int = 1) -> str:\n",
        "    sel = state.selected or {}\n",
        "    blob = {\n",
        "        \"text\": state.last_text or \"\",\n",
        "        \"age\": state.last_age,\n",
        "        \"selected_type\": sel.get(\"chosen_type\",\"none\"),\n",
        "        \"selected_pair\": [sel.get(\"w1\",\"\"), sel.get(\"w2\",\"\")],\n",
        "        \"notes\": \"Use only the selected pair carried from prior analysis.\"\n",
        "    }\n",
        "    prompt = (\n",
        "        _QA_SELECTED_PAIR_INSTRUCTIONS\n",
        "        + \"\\n\\nQUESTION:\\n\" + question.strip()\n",
        "        + \"\\n\\nCONTEXT:\\n\" + json.dumps(blob, ensure_ascii=False, indent=2)\n",
        "        + \"\\n\\nANSWER (plain text, concise):\"\n",
        "    )\n",
        "    last_err = None\n",
        "    for i in range(retries + 1):\n",
        "        try:\n",
        "            r = model_llm.generate_content(prompt)\n",
        "            ans = _safe_take_text(r).strip()\n",
        "            ans = re.sub(r'^\\s*```(?:json)?\\s*', '', ans)\n",
        "            ans = re.sub(r'\\s*```\\s*$', '', ans).strip()\n",
        "            return ans\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if i < retries and any(x in str(e) for x in (\"429\", \"503\")):\n",
        "                time.sleep(1.5 * (i + 1)); continue\n",
        "            break\n",
        "    return f\"[LLM error] {str(last_err)[:200]}\"\n",
        "\n",
        "# ── Conversation memory ───────────────────────────────────────\n",
        "class ConversationState:\n",
        "    def __init__(self, default_age: float = 10):\n",
        "        self.last_text: Optional[str] = None\n",
        "        self.last_age: float = float(default_age)\n",
        "        self.last_feats: Optional[Dict[str,Any]] = None\n",
        "        self.selected: Dict[str, Any] = {\n",
        "            \"chosen_type\": \"none\",\n",
        "            \"w1\": \"\",\n",
        "            \"w2\": \"\",\n",
        "            \"why\": \"\",\n",
        "            \"similarity\": None  # kept for follow-ups, not printed by default\n",
        "        }\n",
        "\n",
        "    def update_selection(self, chosen_type: str, w1: str, w2: str, why: str, similarity: Optional[float]):\n",
        "        self.selected = {\"chosen_type\": chosen_type, \"w1\": w1, \"w2\": w2, \"why\": why, \"similarity\": similarity}\n",
        "\n",
        "    def update_sentence(self, text: str, age: float, feats: Dict[str, Any]):\n",
        "        self.last_text = text\n",
        "        self.last_age = float(age)\n",
        "        self.last_feats = feats\n",
        "\n",
        "STATE = ConversationState(default_age=10)\n",
        "\n",
        "# ── Age/sentence extraction helpers ───────────────────────────\n",
        "_AGE_PAT = re.compile(r\"age\\s*=\\s*(\\d{1,3})\", re.I)\n",
        "\n",
        "def _extract_age(user: str, fallback: float) -> float:\n",
        "    m = _AGE_PAT.search(user)\n",
        "    if m:\n",
        "        try: return float(m.group(1))\n",
        "        except: pass\n",
        "    return float(fallback)\n",
        "\n",
        "def _extract_sentence(user: str, last_text: Optional[str]) -> Optional[str]:\n",
        "    qm = re.findall(r\"“([^”]+)”|\\\"([^\\\"]+)\\\"\", user)\n",
        "    for grp in qm:\n",
        "        inside = grp[0] or grp[1]\n",
        "        if inside and len(inside.split()) >= 2:\n",
        "            return inside.strip()\n",
        "    m = re.search(r\"\\bis\\s+(.+?)\\s+a\\s+pun\\??\", user, flags=re.I)\n",
        "    if m:\n",
        "        cand = m.group(1).strip()\n",
        "        if len(cand.split()) >= 2: return cand\n",
        "    m = re.search(r\"(?:^|\\b)text\\s*:\\s*(.+)$\", user, flags=re.I)\n",
        "    if m: return m.group(1).strip()\n",
        "    if len(user.split()) >= 3 and any(p in user for p in [\".\", \"?\", \"!\", \"—\", \",\"]):\n",
        "        return user.strip()\n",
        "    return last_text\n",
        "\n",
        "# ── Follow-up patterns ────────────────────────────────────────\n",
        "_SIM_PHON_PAT = re.compile(r\"phonetic\\s+similarity\\s+between\\s+([a-z]+)\\s+and\\s+([a-z]+)\", re.I)\n",
        "_SIM_SEM_PAT  = re.compile(r\"semantic\\s+(?:similarity|distance)\\s+between\\s+([a-z]+)\\s+and\\s+([a-z]+)\", re.I)\n",
        "\n",
        "# ── Core analyze+select pipeline (LLM chooses the pair) ───────\n",
        "def _analyze_and_select(text: str, age: float) -> str:\n",
        "    feats = extract_features(text, age)\n",
        "    verdict = analyze_text(text, age)\n",
        "    pun_type = str(verdict.get(\"pun_type\", \"none\")).lower()\n",
        "    if pun_type == \"non-joke\":\n",
        "        pun_type = \"none\"\n",
        "\n",
        "    choice = llm_choose_pair(text, age, pun_type)\n",
        "    chosen_type = choice[\"chosen_type\"]\n",
        "    w1, w2 = choice[\"w1\"], choice[\"w2\"]\n",
        "\n",
        "    # compute but don't print similarity unless asked later\n",
        "    similarity = None\n",
        "    if chosen_type == \"phonetic\" and w1 and w2:\n",
        "        similarity = float(phonetic_similarity(w1, w2))\n",
        "    elif chosen_type == \"semantic\" and w1 and w2:\n",
        "        similarity = float(semantic_similarity(text, w1, w2))\n",
        "\n",
        "    STATE.update_sentence(text, age, feats)\n",
        "    STATE.update_selection(chosen_type, w1, w2, choice.get(\"why\",\"\"), similarity)\n",
        "\n",
        "    is_joke = verdict.get(\"valid_joke\", False)\n",
        "    human = []\n",
        "    human.append(f\"It is {'a pun' if is_joke else 'not a pun'} ({pun_type}).\")\n",
        "    if chosen_type in {\"phonetic\",\"semantic\"} and w1 and w2:\n",
        "        chan = \"sound\" if chosen_type == \"phonetic\" else \"meaning\"\n",
        "        human.append(f\"Selected {chosen_type} pair: '{w1}'–'{w2}' (channel: {chan}).\")\n",
        "    if choice.get(\"why\"):\n",
        "        human.append(choice[\"why\"])\n",
        "    if verdict.get(\"humor_reason\"):\n",
        "        human.append(verdict[\"humor_reason\"])\n",
        "    return \" \".join(human).strip()\n",
        "\n",
        "# ── Router (intent checks BEFORE generic analyze) ─────────────\n",
        "def dispatch(user_query: str, state: ConversationState) -> str:\n",
        "    q = user_query.strip()\n",
        "    ql = q.lower()\n",
        "    age = _extract_age(q, state.last_age)\n",
        "    text = _extract_sentence(q, state.last_text)\n",
        "\n",
        "    # direct similarity queries (explicit ⇒ allowed to print scores)\n",
        "    m = _SIM_PHON_PAT.search(ql)\n",
        "    if m:\n",
        "        w1, w2 = m.group(1), m.group(2)\n",
        "        return f\"Phonetic similarity between '{w1}' and '{w2}' is {phonetic_similarity(w1, w2):.2f}.\"\n",
        "    m = _SIM_SEM_PAT.search(ql)\n",
        "    if m:\n",
        "        w1, w2 = m.group(1), m.group(2)\n",
        "        ctx_text = text or state.last_text or f\"{w1} … {w2}.\"\n",
        "        sim = semantic_similarity(ctx_text, w1, w2)\n",
        "        return f\"Semantic similarity between '{w1}' and '{w2}' is {sim:.2f} (distance {1-sim:.2f}).\"\n",
        "\n",
        "    # follow-ups on the SELECTED pair (explicit similarity ⇒ allowed)\n",
        "    if \"semantic distance between the chosen pair\" in ql or \"semantic similarity of the chosen pair\" in ql:\n",
        "        sel = state.selected\n",
        "        if not sel or sel.get(\"chosen_type\") != \"semantic\" or not (sel.get(\"w1\") and sel.get(\"w2\")):\n",
        "            return \"No semantic pair is selected as it has classified as phonetic.\"\n",
        "        sim = semantic_similarity(state.last_text, sel[\"w1\"], sel[\"w2\"])\n",
        "        state.selected[\"similarity\"] = float(sim)\n",
        "        return f\"Chosen semantic pair '{sel['w1']}'–'{sel['w2']}' has similarity {sim:.2f} (distance {1-sim:.2f}).\"\n",
        "\n",
        "    if \"phonetic similarity of the chosen pair\" in ql or \"sound similarity of the chosen pair\" in ql:\n",
        "        sel = state.selected\n",
        "        if not sel or sel.get(\"chosen_type\") != \"phonetic\" or not (sel.get(\"w1\") and sel.get(\"w2\")):\n",
        "            return \"No phonetic pair is selected as the jokes classified as phonetic.\"\n",
        "        sim = phonetic_similarity(sel[\"w1\"], sel[\"w2\"])\n",
        "        state.selected[\"similarity\"] = float(sim)\n",
        "        return f\"Chosen phonetic pair '{sel['w1']}'–'{sel['w2']}' has phonetic similarity {sim:.2f}.\"\n",
        "\n",
        "    # “what kind of wordplay / pun type / type of pun” — use selected pair (no scores)\n",
        "    if (\"what kind of wordplay\" in ql) or re.search(r\"\\bpun\\s*type\\b\", ql) or re.search(r\"\\btype\\s+of\\s+pun\\b\", ql):\n",
        "        sel = state.selected\n",
        "        if not state.last_text or not sel or sel.get(\"chosen_type\") == \"none\":\n",
        "            return \"Provide a sentence first so I can select a pair (e.g., Is “Water you doing for lunch” a pun? age=10).\"\n",
        "        pt = sel.get(\"chosen_type\", \"none\")\n",
        "        if pt in {\"phonetic\",\"semantic\"}:\n",
        "            reason = sel.get(\"why\",\"The selected pair best matches the detected wordplay channel.\")\n",
        "            return f\"{pt} — {reason}\"\n",
        "        return \"none — no convincing pair was selected for wordplay.\"\n",
        "\n",
        "    # “explain the joke/pun” — use selected pair (no scores)\n",
        "    if \"explain\" in ql and (\"joke\" in ql or \"pun\" in ql):\n",
        "        sel = state.selected\n",
        "        if not state.last_text or not sel or sel.get(\"chosen_type\") == \"none\":\n",
        "            return \"Provide a sentence first so I can select a pair.\"\n",
        "        return qa_on_selected(q, state)\n",
        "\n",
        "    # “Is … a pun?” or sentence present → analyze+select (no scores in summary)\n",
        "    if re.search(r\"\\bis\\s+.+\\bpun\\??\", ql) or (text and len(text.split()) >= 2):\n",
        "        return _analyze_and_select(text, age) if text else \"Please include a sentence.\"\n",
        "\n",
        "    # Generic uncommon questions → LLM QA using selected pair (no scores)\n",
        "    if state.last_text and state.selected and state.selected.get(\"chosen_type\") != \"none\":\n",
        "        return qa_on_selected(q, state)\n",
        "\n",
        "    return \"Tell me what to do (e.g., Is “Water you doing for lunch” a pun? age=10).\"\n",
        "\n",
        "# ── One-box loop with memory + wrapped output ─────────────────\n",
        "print(\"Conversational Agent (memory on) — type 'quit' to exit.\")\n",
        "#print(\"Examples:\")\n",
        "#print('  • Is \"Water you doing for lunch\" a pun? age=10')\n",
        "#print('  • phonetic similarity between x and y')\n",
        "#print('  • semantic distance between the chosen pair')\n",
        "#print('  • semantic similarity of the chosen pair')\n",
        "#print('  • phonetic similarity of the chosen pair')\n",
        "#print('  • what kind of wordplay is involved?')\n",
        "#print('  • explain the joke')\n",
        "\n",
        "\n",
        "while True:\n",
        "    user = input(\"\\nAsk: \").strip()\n",
        "    if user.lower() in {\"quit\", \"exit\"}:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    raw = dispatch(user, STATE)\n",
        "    print(_wrap_by_words(f\"Agent: {raw}\", max_words=10))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}